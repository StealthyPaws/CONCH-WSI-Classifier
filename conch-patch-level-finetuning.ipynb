{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2322642,"sourceType":"datasetVersion","datasetId":1401931},{"sourceId":8799531,"sourceType":"datasetVersion","datasetId":5291418}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install git+https://github.com/Mahmoodlab/CONCH.git","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom pathlib import Path\nimport json\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision.transforms as transforms\nfrom PIL import Image\n\nfrom conch.open_clip_custom import create_model_from_pretrained","metadata":{"execution":{"iopub.status.busy":"2024-07-08T12:55:08.407225Z","iopub.execute_input":"2024-07-08T12:55:08.407601Z","iopub.status.idle":"2024-07-08T12:55:15.306062Z","shell.execute_reply.started":"2024-07-08T12:55:08.40756Z","shell.execute_reply":"2024-07-08T12:55:15.305242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\n\n# Define transformations\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n# transform = transforms.Compose([\n#     transforms.RandomHorizontalFlip(),\n#     transforms.RandomVerticalFlip(),\n#     transforms.RandomRotation(90),\n#     transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n#     transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n#     transforms.ToTensor(),\n#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n# ])\n\n\n# Dataset paths\ntrain_data_path = \"/kaggle/input/train-tcga-coad-msi-mss/tcga_coad_msi_mss/train\"\nval_data_path = \"/kaggle/input/train-tcga-coad-msi-mss/tcga_coad_msi_mss/val\"\n\n# Datasets\ntrain_dataset = ImageFolder(train_data_path, transform=transform)\nval_dataset = ImageFolder(val_data_path, transform=transform)\n\n# Dataloaders\ntrain_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\nval_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n\n# Print class mapping\nif hasattr(train_dataloader.dataset, 'class_to_idx'):\n    idx_to_class = {v: k for k, v in train_dataloader.dataset.class_to_idx.items()}\n    print(idx_to_class)\nelse:\n    raise ValueError('Dataset does not have class_to_idx attribute')\n\nprint(\"Number of training samples: \", len(train_dataloader.dataset))\nprint(\"Number of validation samples: \", len(val_dataloader.dataset))\n","metadata":{"execution":{"iopub.status.busy":"2024-07-08T12:55:15.307612Z","iopub.execute_input":"2024-07-08T12:55:15.307882Z","iopub.status.idle":"2024-07-08T12:56:08.25673Z","shell.execute_reply.started":"2024-07-08T12:55:15.307858Z","shell.execute_reply":"2024-07-08T12:56:08.25591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom conch.open_clip_custom import create_model_from_pretrained\n\n# Freeze the pre-trained layers\nfor param in model.parameters():\n    param.requires_grad = False\n\n# Add a classification head\nnum_classes = 2\nvisual_output_dim = 512  # Update based on the actual output dimension from the visual trunk\nmodel.classification_head = nn.Linear(visual_output_dim, num_classes).to(device)\n\n# Unfreeze the classification head\nfor param in model.classification_head.parameters():\n    param.requires_grad = True\n\n# Define the criterion and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.classification_head.parameters(), lr=1e-4)\n# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-08T09:37:56.030749Z","iopub.execute_input":"2024-07-08T09:37:56.031468Z","iopub.status.idle":"2024-07-08T09:37:56.067809Z","shell.execute_reply.started":"2024-07-08T09:37:56.031437Z","shell.execute_reply":"2024-07-08T09:37:56.066517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training Loop\nnum_epochs = 50\nlosses = []  # List to store losses\nepoch_losses = []  # List to store average losses per epoch\n\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n\n    for i, data in enumerate(train_dataloader):\n        inputs, labels = data[0].to(device), data[1].to(device)\n\n        optimizer.zero_grad()\n\n        # Forward pass\n        image_features, _ = model.visual(inputs)\n        outputs = model.classification_head(image_features)\n        loss = criterion(outputs, labels)\n        \n        # Backward pass and optimization\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n        if i % 100 == 99:    # Print every 100 batches\n            print(f\"[{epoch + 1}, {i + 1}] loss: {running_loss / 100:.3f}\")\n            losses.append((epoch + 1, running_loss / 100))  # Store epoch and average loss\n            running_loss = 0.0\n\n    # Calculate average loss per epoch and store\n    epoch_loss = running_loss / len(train_dataloader)\n    epoch_losses.append((epoch + 1, epoch_loss))\n\nprint(\"Finished Training\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-08T06:46:44.082262Z","iopub.execute_input":"2024-07-08T06:46:44.082673Z","iopub.status.idle":"2024-07-08T07:58:07.311624Z","shell.execute_reply.started":"2024-07-08T06:46:44.082638Z","shell.execute_reply":"2024-07-08T07:58:07.309882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting losses per batch\nimport matplotlib.pyplot as plt\n\nepochs, batch_losses = zip(*losses)\nplt.plot(epochs, batch_losses, label='Batch Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Average Loss')\nplt.title('Training Loss per Batch')\nplt.legend()\nplt.show()\n\n# Plotting average losses per epoch\nepochs, avg_losses = zip(*epoch_losses)\nplt.plot(epochs, avg_losses, label='Average Epoch Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Average Loss')\nplt.title('Training Loss per Epoch')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:58:52.166655Z","iopub.execute_input":"2024-07-08T07:58:52.167039Z","iopub.status.idle":"2024-07-08T07:58:52.763704Z","shell.execute_reply.started":"2024-07-08T07:58:52.167008Z","shell.execute_reply":"2024-07-08T07:58:52.762789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluation\nmodel.eval()\ncorrect = 0\ntotal = 0\n\nwith torch.no_grad():\n    for data in val_dataloader:\n        images, labels = data[0].to(device), data[1].to(device)\n        image_features, _ = model.visual(images)\n        outputs = model.classification_head(image_features)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint(f'Test Accuracy: {100 * correct / total:.2f}%')\n","metadata":{"execution":{"iopub.status.busy":"2024-07-08T15:46:20.335779Z","iopub.execute_input":"2024-07-08T15:46:20.336748Z","iopub.status.idle":"2024-07-08T15:48:29.069893Z","shell.execute_reply.started":"2024-07-08T15:46:20.336705Z","shell.execute_reply":"2024-07-08T15:48:29.068829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()\ncorrect = 0\ntotal = 0\n\nwith torch.no_grad():\n    for data in train_dataloader:\n        images, labels = data[0].to(device), data[1].to(device)\n        image_features, _ = model.visual(images)\n        outputs = model.classification_head(image_features)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint(f'Training Accuracy: {100 * correct / total:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2024-07-08T15:59:46.151686Z","iopub.execute_input":"2024-07-08T15:59:46.15205Z","iopub.status.idle":"2024-07-08T16:02:13.661257Z","shell.execute_reply.started":"2024-07-08T15:59:46.152021Z","shell.execute_reply":"2024-07-08T16:02:13.659947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Test Accuracy: 81.99% --> convergence at 18 epochs \n\n> Training Accuracy: 90.80%","metadata":{}},{"cell_type":"markdown","source":"> 72.58% ---> only trained the classification head and evaluated it  (10 epochs)\n\n> 72.84% ---> only trained the classification head and evaluated it  (30 epochs)\n\n> 65.23% ---> trained model's hyperparams and evaluated classification head \n\n> 68.07% ---> only trained head and changed transformations, evaluated head","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom conch.open_clip_custom import create_model_from_pretrained\n\n# Define transformations\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Dataset paths\ntrain_data_path = \"/kaggle/input/train-tcga-coad-msi-mss/tcga_coad_msi_mss/train\"\nval_data_path = \"/kaggle/input/train-tcga-coad-msi-mss/tcga_coad_msi_mss/val\"\n\n# Datasets\ntrain_dataset = ImageFolder(train_data_path, transform=transform)\nval_dataset = ImageFolder(val_data_path, transform=transform)\n\n# Dataloaders\ntrain_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\nval_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n\n# Print class mapping\nif hasattr(train_dataloader.dataset, 'class_to_idx'):\n    idx_to_class = {v: k for k, v in train_dataloader.dataset.class_to_idx.items()}\n    print(idx_to_class)\nelse:\n    raise ValueError('Dataset does not have class_to_idx attribute')\n\nprint(\"Number of training samples: \", len(train_dataloader.dataset))\nprint(\"Number of validation samples: \", len(val_dataloader.dataset))\n\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\ncheckpoint_path = '/kaggle/input/pytorch-model/pytorch_model.bin'\nmodel, _ = create_model_from_pretrained(model_cfg='conch_ViT-B-16', checkpoint_path=checkpoint_path, device=device)\n_ = model.eval()\n\n# Custom Model with Additional Layers in the Classification Head\nclass CustomModel(nn.Module):\n    def __init__(self, original_model, visual_output_dim, num_classes):\n        super(CustomModel, self).__init__()\n        self.visual = original_model.visual\n        self.classification_head = nn.Sequential(\n            nn.Linear(visual_output_dim, 256),\n            nn.ReLU(),\n            nn.Dropout(p=0.5),\n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.Dropout(p=0.5),\n            nn.Linear(128, num_classes)\n        )\n\n    def forward(self, x):\n        x, _ = self.visual(x)\n        x = self.classification_head(x)\n        return x\n\n# Instantiate the custom model\nmodel = CustomModel(original_model=model, visual_output_dim=512, num_classes=2).to(device)\n\n# Freeze the pre-trained layers\nfor param in model.visual.parameters():\n    param.requires_grad = False\n\n# Define the criterion and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.classification_head.parameters(), lr=1e-4)\n\n# Early stopping parameters\npatience = 10\nmin_delta = 0.001\nbest_loss = float('inf')\npatience_counter = 0\nprev_best_weights_path = None\n\n# Training Loop with Early Stopping\nnum_epochs = 50\nlosses = []  # List to store losses\nepoch_losses = []  # List to store average losses per epoch\nval_losses = []  # List to store validation losses\n\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n\n    for i, data in enumerate(train_dataloader):\n        inputs, labels = data[0].to(device), data[1].to(device)\n\n        optimizer.zero_grad()\n\n        # Forward pass\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        \n        # Backward pass and optimization\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n        if i % 100 == 99:    # Print every 100 batches\n            print(f\"[{epoch + 1}, {i + 1}] loss: {running_loss / 100:.3f}\")\n            losses.append((epoch + 1, running_loss / 100))  # Store epoch and average loss\n            running_loss = 0.0\n\n    # Calculate average loss per epoch and store\n    epoch_loss = running_loss / len(train_dataloader)\n    epoch_losses.append((epoch + 1, epoch_loss))\n\n    # Validation phase\n    model.eval()\n    val_loss = 0.0\n    with torch.no_grad():\n        for data in val_dataloader:\n            inputs, labels = data[0].to(device), data[1].to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n\n    val_loss /= len(val_dataloader)\n    val_losses.append((epoch + 1, val_loss))\n    print(f\"Validation loss after epoch {epoch + 1}: {val_loss:.3f}\")\n\n    # Save the model if validation loss has decreased\n    if val_loss < best_loss - min_delta:\n        best_loss = val_loss\n        patience_counter = 0\n        best_weights_path = f'/kaggle/working/custom_model_weights_epoch_{epoch + 1}.pth'\n        \n        torch.save(model.state_dict(), best_weights_path)\n        print(f\"Model weights saved for epoch {epoch + 1}\")\n        \n        # Delete the previous best weights if they exist\n        if prev_best_weights_path is not None:\n            os.remove(prev_best_weights_path)\n            print(f\"Deleted previous best weights: {prev_best_weights_path}\")\n        \n        prev_best_weights_path = best_weights_path\n    else:\n        patience_counter += 1\n\n    if patience_counter >= patience:\n        print(f\"Early stopping at epoch {epoch + 1}\")\n        break\n\nprint(\"Finished Training\")\n\n# Plotting the loss curve\nimport matplotlib.pyplot as plt\n\nepochs = [x[0] for x in losses]\nloss_values = [x[1] for x in losses]\n\nplt.plot(epochs, loss_values, label='Training Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training Loss Over Time')\nplt.legend()\nplt.show()\n\nval_epochs = [x[0] for x in val_losses]\nval_loss_values = [x[1] for x in val_losses]\n\nplt.plot(val_epochs, val_loss_values, label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Validation Loss Over Time')\nplt.legend()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-08T13:35:14.491963Z","iopub.execute_input":"2024-07-08T13:35:14.492363Z","iopub.status.idle":"2024-07-08T15:44:59.976492Z","shell.execute_reply.started":"2024-07-08T13:35:14.492321Z","shell.execute_reply":"2024-07-08T15:44:59.975554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'custom_model_weights.pth')","metadata":{"execution":{"iopub.status.busy":"2024-07-08T11:06:51.90553Z","iopub.status.idle":"2024-07-08T11:06:51.90589Z","shell.execute_reply.started":"2024-07-08T11:06:51.905725Z","shell.execute_reply":"2024-07-08T11:06:51.905741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}